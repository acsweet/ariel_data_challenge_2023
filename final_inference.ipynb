{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4914b57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model\n",
    "import sys, os, time\n",
    "import h5py\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow_addons.optimizers import CyclicalLearningRate\n",
    "import pickle\n",
    "\n",
    "from utils import get_diag\n",
    "from model import get_model\n",
    "\n",
    "# from competition baseline\n",
    "from base_code.helper import to_observed_matrix\n",
    "from base_code.posterior_utils import compute_posterior_loss, default_prior_bounds\n",
    "from base_code.submit_format import to_competition_format\n",
    "from base_code.FM_utils_final import ariel_resolution, setup_dedicated_fm, initialise_forward_model\n",
    "from base_code.spectral_metric import compute_spectral_loss\n",
    "\n",
    "import taurex.log\n",
    "taurex.log.disableLogging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fd1b74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(ad, s):\n",
    "    ad = ad.copy()\n",
    "    spectra_rw_mean = s.mean(axis=1)\n",
    "    spectra_rw_std = s.std(axis=1)\n",
    "    spectra_rw_min = s.min(axis=1)\n",
    "    spectra_rw_max = s.max(axis=1)\n",
    "        \n",
    "    ad['spectra_rw_mean'] = spectra_rw_mean\n",
    "    ad['spectra_rw_std'] = spectra_rw_std\n",
    "    ad['spectra_rw_min'] = spectra_rw_min\n",
    "    ad['spectra_rw_max'] = spectra_rw_max\n",
    "\n",
    "    ad['planet_mass_kg/star_mass_kg'] = ad['planet_mass_kg']/ad['star_mass_kg']\n",
    "    ad['star_density'] = ad['star_mass_kg']*(4/3)*np.pi*(ad['star_radius_m']**3)\n",
    "    ad['planet_eqlbm_temp'] = np.sqrt(ad['star_radius_m']/(2*ad['planet_distance']))*ad['star_temperature']\n",
    "    ad['planet_semimajor_axis'] = ((ad['star_mass_kg'] + ad['planet_mass_kg'])*((ad['planet_orbital_period']/(2*np.pi))**2))**(1/3)\n",
    "\n",
    "    cols = [c for c in ad.columns if c != 'planet_ID']\n",
    "    for c in cols:\n",
    "        ad[c] = np.log(ad[c])\n",
    "        \n",
    "    return ad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ae12c7",
   "metadata": {},
   "source": [
    "# Load training data and calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a37ae5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume this order?\n",
    "target_labels = ['planet_radius','planet_temp','log_H2O','log_CO2','log_CO','log_CH4','log_NH3']\n",
    "num_targets = len(target_labels)\n",
    "\n",
    "target_scales_dict = {\n",
    "    'planet_radius': [0.1, 3],\n",
    "    'planet_temp': [0, 7000],\n",
    "    'log_H2O': [-12, -1],\n",
    "    'log_CO2': [-12, -1],\n",
    "    'log_CO': [-12, -1],\n",
    "    'log_CH4': [-12, -1],\n",
    "    'log_NH3': [-12, -1]\n",
    "}\n",
    "\n",
    "target_scales_arr = np.array([target_scales_dict[l] for l in target_labels]) # safer, in case dict unordered\n",
    "min_vals = target_scales_arr[:, 0]\n",
    "max_vals = target_scales_arr[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e2102d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust as needed\n",
    "training_path = 'data/FullDataset/TrainingData'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8a642bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_GT_path = os.path.join(training_path, 'Ground Truth Package')\n",
    "GT_trace_path = os.path.join(training_GT_path, 'Tracedata.hdf5')\n",
    "trace_GT = h5py.File(os.path.join(training_GT_path, 'TraceData.hdf5'),\"r\")\n",
    "\n",
    "spectral_training_data = h5py.File(os.path.join(training_path,'SpectralData.hdf5'),\"r\")\n",
    "aux_data = pd.read_csv(os.path.join(training_path,'AuxillaryTable.csv'))\n",
    "soft_label_data = pd.read_csv(os.path.join(training_GT_path, 'FM_Parameter_Table.csv'))\n",
    "\n",
    "trace_file = h5py.File(GT_trace_path)\n",
    "\n",
    "if 'Unnamed: 0' in soft_label_data.columns:\n",
    "    soft_label_data = soft_label_data.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "779b6dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opening existing spec matrix file\n",
      "spectra shape: (41423, 52, 4)\n",
      "spectra mean: 0.008257788618509107, std: 0.011651996038057373\n"
     ]
    }
   ],
   "source": [
    "spec_matrix_file = 'spec_matrix.npy'\n",
    "if spec_matrix_file in os.listdir('data/'):\n",
    "    print('opening existing spec matrix file')\n",
    "    with open('data/spec_matrix.npy', 'rb') as f:\n",
    "        spec_matrix = np.load(f)\n",
    "    print('spectra shape:', spec_matrix.shape)\n",
    "else:\n",
    "    print('constructing spec matrix and saving to file')\n",
    "    start_time = time.time()\n",
    "    spec_matrix = to_observed_matrix(spectral_training_data, aux_data)\n",
    "    with open('data/spec_matrix.npy', 'wb') as f:\n",
    "        np.save(f, spec_matrix)\n",
    "    print(\"finished after: {}, spectral matrix shape: {}\".format(time.time() - start_time, spec_matrix.shape))\n",
    "\n",
    "noise = spec_matrix[:, :, 2]\n",
    "spectra = spec_matrix[:, :, 1]\n",
    "wl_grid = spec_matrix[:, :, 0]\n",
    "bin_width = spec_matrix[:, :, 3]\n",
    "\n",
    "global_spectra_mean = np.mean(spectra)\n",
    "global_spectra_std = np.std(spectra)\n",
    "print(f'spectra mean: {global_spectra_mean}, std: {global_spectra_std}')\n",
    "\n",
    "wl_channels = spectra.shape[1] # wavelength_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c0c0337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading from file\n",
      "has_data: 6766, no_data: 34657\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>planet_id_str</th>\n",
       "      <th>has_trace_data</th>\n",
       "      <th>planet_id</th>\n",
       "      <th>planet_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Planet_train1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>train1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planet_train2</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>train2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Planet_train3</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>train3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Planet_train4</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>train4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Planet_train5</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>train5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   planet_id_str  has_trace_data  planet_id planet_ID\n",
       "0  Planet_train1            True          1    train1\n",
       "1  Planet_train2            True          2    train2\n",
       "2  Planet_train3            True          3    train3\n",
       "3  Planet_train4           False          4    train4\n",
       "4  Planet_train5            True          5    train5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "planet_desc_filename = 'planets_data_desc.csv'\n",
    "\n",
    "if planet_desc_filename in os.listdir():\n",
    "    print('reading from file')\n",
    "    df_planet_has_data = pd.read_csv('planets_data_desc.csv')\n",
    "\n",
    "else:\n",
    "    print('building planet_data_desc')\n",
    "    planet_list = [p for p in trace_file.keys()] \n",
    "\n",
    "    planet_data_existence = []\n",
    "    for idx, pl in enumerate(planet_list):\n",
    "        # print(trace_file[pl]['weights'].shape != ())\n",
    "        has_data = trace_file[pl]['weights'].shape != ()\n",
    "        planet_data_existence.append((pl, has_data))\n",
    "        \n",
    "    print(f'finished, total planets: {len(planet_data_existence)}')\n",
    "    \n",
    "    # convenience stuff\n",
    "    df_planet_has_data = pd.DataFrame(planet_data_existence, columns=['planet_id_str', 'has_trace_data'])\n",
    "    df_planet_has_data['planet_id'] = df_planet_has_data['planet_id_str'].str \\\n",
    "                                                                         .replace('Planet_train', '') \\\n",
    "                                                                         .astype(int)\n",
    "    df_planet_has_data['planet_ID'] = df_planet_has_data['planet_id_str'].str.replace('Planet_', '')\n",
    "    df_planet_has_data = df_planet_has_data.sort_values(by=['planet_id']).reset_index(drop=True)\n",
    "    \n",
    "    df_planet_has_data.to_csv(planet_desc_filename, index=False)\n",
    "    \n",
    "total_with_data = df_planet_has_data['has_trace_data'].sum()\n",
    "print(f'has_data: {total_with_data}, no_data: {df_planet_has_data.shape[0] - total_with_data}')\n",
    "df_planet_has_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9082103b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>planet_ID</th>\n",
       "      <th>planet_radius</th>\n",
       "      <th>planet_temp</th>\n",
       "      <th>log_H2O</th>\n",
       "      <th>log_CO2</th>\n",
       "      <th>log_CO</th>\n",
       "      <th>log_CH4</th>\n",
       "      <th>log_NH3</th>\n",
       "      <th>planet_id_str</th>\n",
       "      <th>has_trace_data</th>\n",
       "      <th>planet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train1</td>\n",
       "      <td>0.559620</td>\n",
       "      <td>863.394770</td>\n",
       "      <td>-8.865868</td>\n",
       "      <td>-6.700707</td>\n",
       "      <td>-5.557561</td>\n",
       "      <td>-8.957615</td>\n",
       "      <td>-3.097540</td>\n",
       "      <td>Planet_train1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train2</td>\n",
       "      <td>1.118308</td>\n",
       "      <td>1201.700465</td>\n",
       "      <td>-4.510258</td>\n",
       "      <td>-8.228966</td>\n",
       "      <td>-3.565427</td>\n",
       "      <td>-7.807424</td>\n",
       "      <td>-3.633658</td>\n",
       "      <td>Planet_train2</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train3</td>\n",
       "      <td>0.400881</td>\n",
       "      <td>1556.096477</td>\n",
       "      <td>-7.225472</td>\n",
       "      <td>-6.931472</td>\n",
       "      <td>-3.081975</td>\n",
       "      <td>-8.567854</td>\n",
       "      <td>-5.378472</td>\n",
       "      <td>Planet_train3</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train4</td>\n",
       "      <td>0.345974</td>\n",
       "      <td>1268.624884</td>\n",
       "      <td>-7.461157</td>\n",
       "      <td>-5.853334</td>\n",
       "      <td>-3.044711</td>\n",
       "      <td>-5.149378</td>\n",
       "      <td>-3.815568</td>\n",
       "      <td>Planet_train4</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train5</td>\n",
       "      <td>0.733184</td>\n",
       "      <td>1707.323564</td>\n",
       "      <td>-4.140844</td>\n",
       "      <td>-7.460278</td>\n",
       "      <td>-3.181793</td>\n",
       "      <td>-5.996593</td>\n",
       "      <td>-4.535345</td>\n",
       "      <td>Planet_train5</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  planet_ID  planet_radius  planet_temp   log_H2O   log_CO2    log_CO  \\\n",
       "0    train1       0.559620   863.394770 -8.865868 -6.700707 -5.557561   \n",
       "1    train2       1.118308  1201.700465 -4.510258 -8.228966 -3.565427   \n",
       "2    train3       0.400881  1556.096477 -7.225472 -6.931472 -3.081975   \n",
       "3    train4       0.345974  1268.624884 -7.461157 -5.853334 -3.044711   \n",
       "4    train5       0.733184  1707.323564 -4.140844 -7.460278 -3.181793   \n",
       "\n",
       "    log_CH4   log_NH3  planet_id_str  has_trace_data  planet_id  \n",
       "0 -8.957615 -3.097540  Planet_train1            True          1  \n",
       "1 -7.807424 -3.633658  Planet_train2            True          2  \n",
       "2 -8.567854 -5.378472  Planet_train3            True          3  \n",
       "3 -5.149378 -3.815568  Planet_train4           False          4  \n",
       "4 -5.996593 -4.535345  Planet_train5            True          5  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_for_split = ['planet_ID', 'planet_temp', 'planet_radius']\n",
    "soft_d_has_trace = soft_label_data.merge(df_planet_has_data, on='planet_ID')\n",
    "soft_d_has_trace.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d3af136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_shape: (37280, 11), test_shape: (4143, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>planet_ID</th>\n",
       "      <th>planet_radius</th>\n",
       "      <th>planet_temp</th>\n",
       "      <th>log_H2O</th>\n",
       "      <th>log_CO2</th>\n",
       "      <th>log_CO</th>\n",
       "      <th>log_CH4</th>\n",
       "      <th>log_NH3</th>\n",
       "      <th>planet_id_str</th>\n",
       "      <th>has_trace_data</th>\n",
       "      <th>planet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24311</th>\n",
       "      <td>train24312</td>\n",
       "      <td>0.173529</td>\n",
       "      <td>807.875012</td>\n",
       "      <td>-4.835660</td>\n",
       "      <td>-8.588479</td>\n",
       "      <td>-4.651833</td>\n",
       "      <td>-5.617772</td>\n",
       "      <td>-7.336094</td>\n",
       "      <td>Planet_train24312</td>\n",
       "      <td>False</td>\n",
       "      <td>24312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>train1108</td>\n",
       "      <td>0.156580</td>\n",
       "      <td>611.859047</td>\n",
       "      <td>-6.332634</td>\n",
       "      <td>-4.279123</td>\n",
       "      <td>-3.590717</td>\n",
       "      <td>-4.503540</td>\n",
       "      <td>-4.024263</td>\n",
       "      <td>Planet_train1108</td>\n",
       "      <td>False</td>\n",
       "      <td>1108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39362</th>\n",
       "      <td>train39363</td>\n",
       "      <td>0.959320</td>\n",
       "      <td>1615.958900</td>\n",
       "      <td>-8.835347</td>\n",
       "      <td>-5.211572</td>\n",
       "      <td>-5.303128</td>\n",
       "      <td>-7.085874</td>\n",
       "      <td>-4.611678</td>\n",
       "      <td>Planet_train39363</td>\n",
       "      <td>True</td>\n",
       "      <td>39363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1133</th>\n",
       "      <td>train1134</td>\n",
       "      <td>0.223296</td>\n",
       "      <td>871.099229</td>\n",
       "      <td>-5.845370</td>\n",
       "      <td>-7.554668</td>\n",
       "      <td>-4.676774</td>\n",
       "      <td>-4.889590</td>\n",
       "      <td>-6.492952</td>\n",
       "      <td>Planet_train1134</td>\n",
       "      <td>False</td>\n",
       "      <td>1134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7932</th>\n",
       "      <td>train7933</td>\n",
       "      <td>0.146215</td>\n",
       "      <td>933.031771</td>\n",
       "      <td>-3.212717</td>\n",
       "      <td>-6.946803</td>\n",
       "      <td>-3.745800</td>\n",
       "      <td>-7.427348</td>\n",
       "      <td>-6.925160</td>\n",
       "      <td>Planet_train7933</td>\n",
       "      <td>False</td>\n",
       "      <td>7933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        planet_ID  planet_radius  planet_temp   log_H2O   log_CO2    log_CO  \\\n",
       "24311  train24312       0.173529   807.875012 -4.835660 -8.588479 -4.651833   \n",
       "1107    train1108       0.156580   611.859047 -6.332634 -4.279123 -3.590717   \n",
       "39362  train39363       0.959320  1615.958900 -8.835347 -5.211572 -5.303128   \n",
       "1133    train1134       0.223296   871.099229 -5.845370 -7.554668 -4.676774   \n",
       "7932    train7933       0.146215   933.031771 -3.212717 -6.946803 -3.745800   \n",
       "\n",
       "        log_CH4   log_NH3      planet_id_str  has_trace_data  planet_id  \n",
       "24311 -5.617772 -7.336094  Planet_train24312           False      24312  \n",
       "1107  -4.503540 -4.024263   Planet_train1108           False       1108  \n",
       "39362 -7.085874 -4.611678  Planet_train39363            True      39363  \n",
       "1133  -4.889590 -6.492952   Planet_train1134           False       1134  \n",
       "7932  -7.427348 -6.925160   Planet_train7933           False       7933  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(soft_d_has_trace, \n",
    "                train_size=0.9,\n",
    "                random_state=42)\n",
    "print(f'train_shape: {train.shape}, test_shape: {test.shape}')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f15c52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = train.loc[train['has_trace_data']].index # train.index\n",
    "test_idx = test.loc[test['has_trace_data']].index # test.index\n",
    "\n",
    "test_spectra = spectra[test_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26982e2f",
   "metadata": {},
   "source": [
    "# Guassian Multivariate check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6a8a6bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_pickles = [\n",
    "    'multi_gauss_scaler_fold_0_of_5.pickle',\n",
    "    'multi_gauss_scaler_fold_1_of_5.pickle',\n",
    "    'multi_gauss_scaler_fold_2_of_5.pickle',\n",
    "    'multi_gauss_scaler_fold_3_of_5.pickle',\n",
    "    'multi_gauss_scaler_fold_4_of_5.pickle'\n",
    "]\n",
    "\n",
    "model_checkpoints = [\n",
    "    './weights/stage_2_gauss_multivariate_fold_0_of_5',\n",
    "    './weights/stage_2_gauss_multivariate_fold_1_of_5',\n",
    "    './weights/stage_2_gauss_multivariate_fold_2_of_5',\n",
    "    './weights/stage_2_gauss_multivariate_fold_3_of_5',\n",
    "    './weights/stage_2_gauss_multivariate_fold_4_of_5'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c507e2b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ax = get_data(aux_data, spectra, method='kfold')\n",
    "len(ax.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0a0078dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ./weights/stage_2_gauss_multivariate_fold_0_of_5\n",
      "1/1 [==============================] - 0s 478ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_30688\\102697444.py:42: RuntimeWarning: covariance is not positive-semidefinite.\n",
      "  _y_pred_sample = np.random.multivariate_normal(mu[i], Sigma[i], instances)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished 0 after 1.8783197402954102, rows: 665, samples: 4500\n",
      "loading ./weights/stage_2_gauss_multivariate_fold_1_of_5\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "finished 1 after 1.1946825981140137, rows: 665, samples: 4500\n",
      "loading ./weights/stage_2_gauss_multivariate_fold_2_of_5\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "finished 2 after 1.4869976043701172, rows: 665, samples: 4500\n",
      "loading ./weights/stage_2_gauss_multivariate_fold_3_of_5\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "finished 3 after 1.1797845363616943, rows: 665, samples: 4500\n",
      "loading ./weights/stage_2_gauss_multivariate_fold_4_of_5\n",
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_30688\\102697444.py:42: RuntimeWarning: covariance is not positive-semidefinite.\n",
      "  _y_pred_sample = np.random.multivariate_normal(mu[i], Sigma[i], instances)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished 4 after 1.2572643756866455, rows: 665, samples: 4500\n"
     ]
    }
   ],
   "source": [
    "loss = 'chol'\n",
    "n_feature_cols = None\n",
    "num_spectra_features = wl_channels\n",
    "num_added_features = 16 # len(aux_columns) - 1\n",
    "\n",
    "model = get_model(loss, num_spectra_features, n_feature_cols, num_added_features, num_targets)\n",
    "\n",
    "instances = 4500 # 2500 + 500 + 1000 + 500\n",
    "g_y_pred_test = np.zeros((len(model_checkpoints)*instances, len(test_idx), num_targets))\n",
    "    \n",
    "for j, (scaler_file, model_ckpt) in enumerate(zip(scaler_pickles, model_checkpoints)):\n",
    "    start_time = time.time()\n",
    "    with open('saved_objects/' + scaler_file, 'rb') as f:\n",
    "        aux_data_scaler = pickle.load(f)\n",
    "        \n",
    "    _aux_data = get_data(aux_data, spectra)\n",
    "    aux_columns = _aux_data.columns\n",
    "    test_aux_data = _aux_data[aux_columns].iloc[test_idx]\n",
    "    \n",
    "    # num_added_features = len(aux_columns) - 1\n",
    "    std_test_aux_data = aux_data_scaler.transform(test_aux_data.drop(['planet_ID'], axis=1).values)\n",
    "    \n",
    "    print(f'loading {model_ckpt}')\n",
    "    model.load_weights(model_ckpt).expect_partial()\n",
    "    \n",
    "    _test_spectra = test_spectra - np.mean(test_spectra, axis=1).reshape((-1, 1))\n",
    "    _x_data = [_test_spectra, std_test_aux_data]\n",
    "    gauss_y_pred = model.predict(_x_data, verbose=1, batch_size=5000) # will this batch size work??\n",
    "    \n",
    "    mu = gauss_y_pred[:, :num_targets]\n",
    "    L  = gauss_y_pred[:, num_targets:]\n",
    "    L, diag = get_diag(gauss_y_pred, num_targets, gauss_y_pred.shape[0])\n",
    "    LT = tf.transpose(L, perm=[0,2,1])\n",
    "    Sigma = tf.linalg.inv(tf.matmul(L, LT))\n",
    "\n",
    "    for i in range(len(test_idx)):\n",
    "        _y_pred_sample = np.random.multivariate_normal(mu[i], Sigma[i], instances)\n",
    "        g_y_pred_test[j*instances:(j+1)*instances, i, :] += _y_pred_sample\n",
    "        \n",
    "    print(f'finished {j} after {time.time() - start_time}, rows: {len(test_idx)}, samples: {instances}')\n",
    "        \n",
    "del(model)\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "da8311e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_vals = target_scales_arr[:, 0]\n",
    "max_vals = target_scales_arr[:, 1]\n",
    "_y_pred_test = g_y_pred_test.reshape(-1, num_targets)\n",
    "g_y_pred_test_org = (_y_pred_test*(max_vals - min_vals)) + min_vals # TODO: wrap this in a function\n",
    "g_y_pred_test_org = g_y_pred_test_org.reshape(len(model_checkpoints)*instances, len(test_idx), num_targets)\n",
    "g_y_pred_test_org = np.swapaxes(g_y_pred_test_org, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "36123396",
   "metadata": {},
   "outputs": [],
   "source": [
    "mg_individual_model_outputs = []\n",
    "mg_folded_model_outputs = []\n",
    "mg_best_model_outputs = []\n",
    "mg_merge_with_uniform_model_outputs = []\n",
    "\n",
    "indivual_model_sample_size = 2500\n",
    "folded_model_sample_size = 500\n",
    "final_grouping = 1000\n",
    "group_with_uniform_sample_size = 500\n",
    "sampled_sizes = [indivual_model_sample_size, folded_model_sample_size, final_grouping, group_with_uniform_sample_size]\n",
    "cumulative_sizes = np.cumsum(sampled_sizes)\n",
    "sampled_size = np.sum(sampled_sizes)\n",
    "for i in range(5):\n",
    "    _mg_y_preds = g_y_pred_test_org[:, i*sampled_size:(i+1)*sampled_size, :].copy()\n",
    "    mg_individual_model_outputs.append(_mg_y_preds[:, :cumulative_sizes[0], :])\n",
    "    mg_folded_model_outputs.append(_mg_y_preds[:, cumulative_sizes[0]:cumulative_sizes[1], :])\n",
    "    mg_best_model_outputs.append(_mg_y_preds[:, cumulative_sizes[1]:cumulative_sizes[2], :])\n",
    "    mg_merge_with_uniform_model_outputs.append(_mg_y_preds[:, cumulative_sizes[2]:, :])\n",
    "    \n",
    "mg_folded_model_outputs_arr = np.concatenate(mg_folded_model_outputs, axis=1)\n",
    "mg_best_model_outputs_arr = np.concatenate([mg_best_model_outputs[0], mg_best_model_outputs[4]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d33c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mg_avg_posterior_scores = []\n",
    "# mg_posterior_scores_list = []\n",
    "# for _pred_arr in mg_individual_model_outputs + [mg_folded_model_outputs_arr, mg_best_model_outputs_arr]:\n",
    "#     tr1 = _pred_arr\n",
    "#     # assume equal importance weights\n",
    "#     weights1 = np.ones((tr1.shape[0], tr1.shape[1]))/np.sum(np.ones(tr1.shape[1]))\n",
    "\n",
    "#     posterior_scores = []\n",
    "#     bounds_matrix = default_prior_bounds()\n",
    "#     for idx, pl_idx in enumerate(test_idx):\n",
    "#         tr_GT = trace_GT[f'Planet_train{pl_idx+1}']['tracedata'][()]\n",
    "#         weights_GT = trace_GT[f'Planet_train{pl_idx+1}']['weights'][()]\n",
    "#         # ignore rows missing ground truth\n",
    "#         if np.isnan(tr_GT).sum() == 1:\n",
    "#             continue\n",
    "#         # compute posterior loss\n",
    "#         score = compute_posterior_loss(tr1[idx], weights1[idx], tr_GT, weights_GT, bounds_matrix)\n",
    "#         posterior_scores.append(score)\n",
    "\n",
    "#     avg_posterior_score = np.mean(posterior_scores)\n",
    "#     print(avg_posterior_score)\n",
    "#     mg_avg_posterior_scores.append(avg_posterior_score)\n",
    "#     mg_posterior_scores_list.append(posterior_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c78757e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.histplot(mg_posterior_scores_list[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "48a8b792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tr1 = g_y_pred_test_org\n",
    "# weights1 = np.ones((tr1.shape[0], tr1.shape[1]))/np.sum(np.ones(tr1.shape[1]))\n",
    "\n",
    "# posterior_scores = []\n",
    "# bounds_matrix = default_prior_bounds()\n",
    "# for idx, pl_idx in enumerate(test_idx):\n",
    "#     tr_GT = trace_GT[f'Planet_train{pl_idx+1}']['tracedata'][()]\n",
    "#     weights_GT = trace_GT[f'Planet_train{pl_idx+1}']['weights'][()]\n",
    "#     ## skip cases with no ground truth\n",
    "#     if np.isnan(tr_GT).sum() == 1:\n",
    "#         continue\n",
    "#     # compute posterior loss\n",
    "#     score = compute_posterior_loss(tr1[idx], weights1[idx], tr_GT, weights_GT, bounds_matrix)\n",
    "#     posterior_scores.append(score)\n",
    "\n",
    "# avg_posterior_score = np.mean(posterior_scores)\n",
    "\n",
    "# avg_posterior_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bae4cb1",
   "metadata": {},
   "source": [
    "# Uniform check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7339583f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_pickles = [\n",
    "    'uniform_percentile_fold_0_of_5.pickle',\n",
    "    'uniform_percentile_fold_1_of_5.pickle',\n",
    "    'uniform_percentile_fold_2_of_5.pickle',\n",
    "    'uniform_percentile_fold_3_of_5.pickle',\n",
    "    'uniform_percentile_fold_4_of_5.pickle'\n",
    "]\n",
    "\n",
    "model_checkpoints = [\n",
    "    './weights/stage_2_uniform_quantiles_fold_0_of_5',\n",
    "    './weights/stage_2_uniform_quantiles_fold_1_of_5',\n",
    "    './weights/stage_2_uniform_quantiles_fold_2_of_5',\n",
    "    './weights/stage_2_uniform_quantiles_fold_3_of_5',\n",
    "    './weights/stage_2_uniform_quantiles_fold_4_of_5'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "12d5b93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ./weights/stage_2_uniform_quantiles_fold_0_of_5\n",
      "1/1 [==============================] - 1s 510ms/step\n",
      "finished 0 after 1.3817200660705566, rows: 665, samples: 4500\n",
      "loading ./weights/stage_2_uniform_quantiles_fold_1_of_5\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "finished 1 after 0.8819115161895752, rows: 665, samples: 4500\n",
      "loading ./weights/stage_2_uniform_quantiles_fold_2_of_5\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "finished 2 after 0.8535933494567871, rows: 665, samples: 4500\n",
      "loading ./weights/stage_2_uniform_quantiles_fold_3_of_5\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "finished 3 after 0.8980004787445068, rows: 665, samples: 4500\n",
      "loading ./weights/stage_2_uniform_quantiles_fold_4_of_5\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "finished 4 after 0.8352808952331543, rows: 665, samples: 4500\n"
     ]
    }
   ],
   "source": [
    "loss = 'uniform_quantiles'\n",
    "n_feature_cols = None\n",
    "num_spectra_features = wl_channels\n",
    "quantile_percents = [0.05, 0.5, 0.95]\n",
    "\n",
    "num_targets = len(target_labels)\n",
    "num_rows = test_spectra.shape[0]\n",
    "num_samples = 3500 # 2500 + 500 + 500 for each fold \n",
    "\n",
    "y_pred_scaled = np.zeros((num_rows, num_samples*len(model_checkpoints), num_targets))\n",
    "\n",
    "model = get_model(loss, num_spectra_features, n_feature_cols, num_added_features, num_targets, \n",
    "                  target_labels=target_labels, quantile_percents=quantile_percents)\n",
    "    \n",
    "for j, (scaler_file, model_ckpt) in enumerate(zip(scaler_pickles, model_checkpoints)):\n",
    "    start_time = time.time()\n",
    "    with open('saved_objects/' + scaler_file, 'rb') as f:\n",
    "        aux_data_scaler = pickle.load(f)\n",
    "        \n",
    "    _aux_data = get_data(aux_data, spectra)\n",
    "    aux_columns = _aux_data.columns\n",
    "    test_aux_data = _aux_data[aux_columns].iloc[test_idx]\n",
    "    \n",
    "    # num_added_features = len(aux_columns) - 1\n",
    "    std_test_aux_data = aux_data_scaler.transform(test_aux_data.drop(['planet_ID'], axis=1).values)\n",
    "    print(f'loading {model_ckpt}')\n",
    "    model.load_weights(model_ckpt).expect_partial()\n",
    "    \n",
    "    _test_spectra = test_spectra - np.mean(test_spectra, axis=1).reshape((-1, 1))\n",
    "    _x_data = [_test_spectra, std_test_aux_data]\n",
    "    y_pred = model.predict(_x_data, verbose=1, batch_size=5000)\n",
    "    for t_id in range(len(target_labels)):\n",
    "        for i in range(num_samples):\n",
    "            y_pred_scaled[:, i + j*num_samples, t_id] += np.random.uniform(low=y_pred[t_id][:, 0], high=y_pred[t_id][:, -1], size=None)\n",
    "            \n",
    "    print(f'finished {j} after {time.time() - start_time}, rows: {len(test_idx)}, samples: {num_samples}')\n",
    "\n",
    "del(model)\n",
    "tf.keras.backend.clear_session()\n",
    "            \n",
    "y_pred_unscaled = (y_pred_scaled*(max_vals - min_vals)) + min_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f5278932",
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_model_outputs = []\n",
    "folded_model_outputs = []\n",
    "merge_with_mg_model_outputs = []\n",
    "indivual_model_sample_size = 2500\n",
    "folded_model_sample_size = 500\n",
    "merge_with_mg_sample_size = 500\n",
    "sampled_sizes = [indivual_model_sample_size, folded_model_sample_size, merge_with_mg_sample_size]\n",
    "cumulative_sizes = np.cumsum(sampled_sizes)\n",
    "sampled_size = np.sum(sampled_sizes)\n",
    "for i in range(5):\n",
    "    _y_preds = y_pred_unscaled[:, i*sampled_size:(i+1)*sampled_size, :].copy()\n",
    "    individual_model_outputs.append(_y_preds[:, :cumulative_sizes[0], :])\n",
    "    folded_model_outputs.append(_y_preds[:, cumulative_sizes[0]:cumulative_sizes[1], :])\n",
    "    merge_with_mg_model_outputs.append(_y_preds[:, cumulative_sizes[1]:, :])\n",
    "    \n",
    "folded_model_outputs_arr = np.concatenate(folded_model_outputs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d59432a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "662.6361331901182\n",
      "660.1087862513427\n",
      "662.8707196562837\n",
      "660.0282706766918\n",
      "653.3791621911922\n",
      "696.4848979591836\n"
     ]
    }
   ],
   "source": [
    "# avg_posterior_scores = []\n",
    "# posterior_scores_list = []\n",
    "# for _pred_arr in individual_model_outputs + [folded_model_outputs_arr]:\n",
    "#     tr1 = _pred_arr\n",
    "#     # assume equal importance weights\n",
    "#     weights1 = np.ones((tr1.shape[0], tr1.shape[1]))/np.sum(np.ones(tr1.shape[1]))\n",
    "\n",
    "#     posterior_scores = []\n",
    "#     planet_ids = []\n",
    "#     bounds_matrix = default_prior_bounds()\n",
    "#     for idx, pl_idx in enumerate(test_idx):\n",
    "#         tr_GT = trace_GT[f'Planet_train{pl_idx+1}']['tracedata'][()]\n",
    "#         weights_GT = trace_GT[f'Planet_train{pl_idx+1}']['weights'][()]\n",
    "#         # ignore rows missing ground truth\n",
    "#         if np.isnan(tr_GT).sum() == 1:\n",
    "#             continue\n",
    "#         # compute posterior loss\n",
    "#         score = compute_posterior_loss(tr1[idx], weights1[idx], tr_GT, weights_GT, bounds_matrix)\n",
    "#         posterior_scores.append(score)\n",
    "#         planet_ids.append(pl_idx)\n",
    "\n",
    "#     avg_posterior_score = np.mean(posterior_scores)\n",
    "#     print(avg_posterior_score)\n",
    "#     avg_posterior_scores.append(avg_posterior_score)\n",
    "#     posterior_scores_list.append(posterior_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "271c160f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_0</th>\n",
       "      <th>model_1</th>\n",
       "      <th>model_2</th>\n",
       "      <th>model_3</th>\n",
       "      <th>model_4</th>\n",
       "      <th>model_5</th>\n",
       "      <th>planet_idx</th>\n",
       "      <th>planet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>760.285714</td>\n",
       "      <td>732.800000</td>\n",
       "      <td>718.114286</td>\n",
       "      <td>822.857143</td>\n",
       "      <td>716.000000</td>\n",
       "      <td>793.714286</td>\n",
       "      <td>4449</td>\n",
       "      <td>Planet_train4450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>470.342857</td>\n",
       "      <td>467.371429</td>\n",
       "      <td>428.285714</td>\n",
       "      <td>413.885714</td>\n",
       "      <td>506.285714</td>\n",
       "      <td>528.571429</td>\n",
       "      <td>4178</td>\n",
       "      <td>Planet_train4179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>652.628571</td>\n",
       "      <td>641.257143</td>\n",
       "      <td>624.800000</td>\n",
       "      <td>608.971429</td>\n",
       "      <td>571.028571</td>\n",
       "      <td>679.828571</td>\n",
       "      <td>40300</td>\n",
       "      <td>Planet_train40301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>710.457143</td>\n",
       "      <td>649.828571</td>\n",
       "      <td>602.171429</td>\n",
       "      <td>710.171429</td>\n",
       "      <td>656.800000</td>\n",
       "      <td>713.942857</td>\n",
       "      <td>3161</td>\n",
       "      <td>Planet_train3162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>791.600000</td>\n",
       "      <td>758.057143</td>\n",
       "      <td>833.200000</td>\n",
       "      <td>756.000000</td>\n",
       "      <td>778.057143</td>\n",
       "      <td>810.571429</td>\n",
       "      <td>3601</td>\n",
       "      <td>Planet_train3602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model_0     model_1     model_2     model_3     model_4     model_5  \\\n",
       "0  760.285714  732.800000  718.114286  822.857143  716.000000  793.714286   \n",
       "1  470.342857  467.371429  428.285714  413.885714  506.285714  528.571429   \n",
       "2  652.628571  641.257143  624.800000  608.971429  571.028571  679.828571   \n",
       "3  710.457143  649.828571  602.171429  710.171429  656.800000  713.942857   \n",
       "4  791.600000  758.057143  833.200000  756.000000  778.057143  810.571429   \n",
       "\n",
       "   planet_idx             planet  \n",
       "0        4449   Planet_train4450  \n",
       "1        4178   Planet_train4179  \n",
       "2       40300  Planet_train40301  \n",
       "3        3161   Planet_train3162  \n",
       "4        3601   Planet_train3602  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict = {\n",
    "    f'model_{i}': scores for i, scores in enumerate(posterior_scores_list)\n",
    "}\n",
    "df_uniform_posterior_scores = pd.DataFrame(data_dict)\n",
    "df_uniform_posterior_scores['planet_idx'] = planet_ids\n",
    "df_uniform_posterior_scores['planet'] = df_uniform_posterior_scores['planet_idx'].apply(lambda x: f'Planet_train{x+1}')\n",
    "\n",
    "df_uniform_posterior_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "049eb9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uniform_posterior_scores.to_csv('uniform_models_posterior_scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c939aa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.histplot(posterior_scores_list[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "adbd6aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tr1 = y_pred_unscaled\n",
    "# # weight takes into account the importance of each point in the tracedata. \n",
    "# # for now we just assume them to be equally weighted\n",
    "# weights1 = np.ones((tr1.shape[0], tr1.shape[1]))/np.sum(np.ones(tr1.shape[1]))\n",
    "\n",
    "# posterior_scores = []\n",
    "# bounds_matrix = default_prior_bounds()\n",
    "# for idx, pl_idx in enumerate(val_idx):\n",
    "#     tr_GT = trace_GT[f'Planet_train{pl_idx+1}']['tracedata'][()]\n",
    "#     weights_GT = trace_GT[f'Planet_train{pl_idx+1}']['weights'][()]\n",
    "#     ## there are cases without ground truth, we will skip over them for this baseline\n",
    "#     ## but every example in leaderboard and final evaluation set will have a complementary ground truth\n",
    "#     if np.isnan(tr_GT).sum() == 1:\n",
    "#         continue\n",
    "#     # compute posterior loss\n",
    "#     score = compute_posterior_loss(tr1[idx], weights1[idx], tr_GT, weights_GT, bounds_matrix)\n",
    "#     posterior_scores.append(score)\n",
    "\n",
    "# avg_posterior_score = np.mean(posterior_scores)\n",
    "# print(avg_posterior_score)\n",
    "# sns.histplot(posterior_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416f792f",
   "metadata": {},
   "source": [
    "# Full evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8e9006ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mg_fold_0', 'mg_fold_1', 'mg_fold_2', 'mg_fold_3', 'mg_fold_4', 'mg_all_folds', 'mg_best_folds', 'uniform_fold_0', 'uniform_fold_1', 'uniform_fold_2', 'uniform_fold_3', 'uniform_fold_4', 'uniform_all_folds', 'best_mg_folds_and_all_uniform_folds'])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mg_outputs_dict = {f'mg_fold_{k}': _arr for k, _arr in enumerate(mg_individual_model_outputs)}\n",
    "mg_outputs_dict['mg_all_folds'] = mg_folded_model_outputs_arr\n",
    "mg_outputs_dict['mg_best_folds'] = mg_best_model_outputs_arr\n",
    "\n",
    "uniform_outputs_dict = {f'uniform_fold_{k}': _arr for k, _arr in enumerate(individual_model_outputs)}\n",
    "uniform_outputs_dict['uniform_all_folds'] = folded_model_outputs_arr\n",
    "\n",
    "total_outputs_dict = {**mg_outputs_dict, **uniform_outputs_dict}\n",
    "_arr = merge_with_mg_model_outputs + [mg_merge_with_uniform_model_outputs[0], mg_merge_with_uniform_model_outputs[4]]\n",
    "total_outputs_dict['best_mg_folds_and_all_uniform_folds'] = np.concatenate(_arr, axis=1)\n",
    "total_outputs_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3fb26b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing mg_fold_0\n",
      "\ttrace shape: (665, 2500, 7)\n",
      "\tavg_posterior_score: 686.2922448979592\n",
      "processing mg_fold_1\n",
      "\ttrace shape: (665, 2500, 7)\n",
      "\tavg_posterior_score: 568.0599785177229\n",
      "processing mg_fold_2\n",
      "\ttrace shape: (665, 2500, 7)\n",
      "\tavg_posterior_score: 488.0128893662728\n",
      "processing mg_fold_3\n",
      "\ttrace shape: (665, 2500, 7)\n",
      "\tavg_posterior_score: 483.5508485499463\n",
      "processing mg_fold_4\n",
      "\ttrace shape: (665, 2500, 7)\n",
      "\tavg_posterior_score: 632.1612889366272\n",
      "processing mg_all_folds\n",
      "\ttrace shape: (665, 2500, 7)\n",
      "\tavg_posterior_score: 615.0172287862513\n",
      "processing mg_best_folds\n",
      "\ttrace shape: (665, 2000, 7)\n",
      "\tavg_posterior_score: 690.7070891514501\n",
      "processing uniform_fold_0\n",
      "\ttrace shape: (665, 2500, 7)\n",
      "\tavg_posterior_score: 662.7546294307197\n",
      "processing uniform_fold_1\n",
      "\ttrace shape: (665, 2500, 7)\n",
      "\tavg_posterior_score: 660.1757250268529\n",
      "processing uniform_fold_2\n",
      "\ttrace shape: (665, 2500, 7)\n",
      "\tavg_posterior_score: 662.9932545649839\n",
      "processing uniform_fold_3\n",
      "\ttrace shape: (665, 2500, 7)\n",
      "\tavg_posterior_score: 660.0531901181525\n",
      "processing uniform_fold_4\n",
      "\ttrace shape: (665, 2500, 7)\n",
      "\tavg_posterior_score: 653.360171858217\n",
      "processing uniform_all_folds\n",
      "\ttrace shape: (665, 2500, 7)\n",
      "\tavg_posterior_score: 696.4252631578948\n",
      "processing best_mg_folds_and_all_uniform_folds\n",
      "\ttrace shape: (665, 3500, 7)\n",
      "\tavg_posterior_score: 696.488015958263\n"
     ]
    }
   ],
   "source": [
    "avg_posterior_scores = []\n",
    "posterior_scores_list = []\n",
    "for _model, _pred_arr in total_outputs_dict.items():\n",
    "    print(f'processing {_model}')\n",
    "    tr1 = _pred_arr\n",
    "    print(f'\\ttrace shape: {tr1.shape}')\n",
    "    \n",
    "    # assume equal importance weights\n",
    "    weights1 = np.ones((tr1.shape[0], tr1.shape[1]))/np.sum(np.ones(tr1.shape[1]))\n",
    "\n",
    "    posterior_scores = []\n",
    "    planet_ids = []\n",
    "    bounds_matrix = default_prior_bounds()\n",
    "    for idx, pl_idx in enumerate(test_idx):\n",
    "        tr_GT = trace_GT[f'Planet_train{pl_idx+1}']['tracedata'][()]\n",
    "        weights_GT = trace_GT[f'Planet_train{pl_idx+1}']['weights'][()]\n",
    "        \n",
    "        # ignore rows missing ground truth\n",
    "        if np.isnan(tr_GT).sum() == 1:\n",
    "            continue\n",
    "            \n",
    "        # compute posterior loss\n",
    "        score = compute_posterior_loss(tr1[idx], weights1[idx], tr_GT, weights_GT, bounds_matrix)\n",
    "        posterior_scores.append(score)\n",
    "        planet_ids.append(pl_idx)\n",
    "\n",
    "    avg_posterior_score = np.mean(posterior_scores)\n",
    "    print(f'\\tavg_posterior_score: {avg_posterior_score}')\n",
    "    avg_posterior_scores.append(avg_posterior_score)\n",
    "    posterior_scores_list.append(posterior_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "97f74f89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mg_fold_0</th>\n",
       "      <th>mg_fold_1</th>\n",
       "      <th>mg_fold_2</th>\n",
       "      <th>mg_fold_3</th>\n",
       "      <th>mg_fold_4</th>\n",
       "      <th>mg_all_folds</th>\n",
       "      <th>mg_best_folds</th>\n",
       "      <th>uniform_fold_0</th>\n",
       "      <th>uniform_fold_1</th>\n",
       "      <th>uniform_fold_2</th>\n",
       "      <th>uniform_fold_3</th>\n",
       "      <th>uniform_fold_4</th>\n",
       "      <th>uniform_all_folds</th>\n",
       "      <th>best_mg_folds_and_all_uniform_folds</th>\n",
       "      <th>planet_idx</th>\n",
       "      <th>planet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>729.885714</td>\n",
       "      <td>430.514286</td>\n",
       "      <td>535.314286</td>\n",
       "      <td>556.171429</td>\n",
       "      <td>712.742857</td>\n",
       "      <td>651.485714</td>\n",
       "      <td>742.428571</td>\n",
       "      <td>759.600000</td>\n",
       "      <td>721.371429</td>\n",
       "      <td>726.742857</td>\n",
       "      <td>820.457143</td>\n",
       "      <td>715.371429</td>\n",
       "      <td>797.028571</td>\n",
       "      <td>778.204082</td>\n",
       "      <td>4449</td>\n",
       "      <td>Planet_train4450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>454.457143</td>\n",
       "      <td>529.771429</td>\n",
       "      <td>465.885714</td>\n",
       "      <td>421.314286</td>\n",
       "      <td>628.114286</td>\n",
       "      <td>560.571429</td>\n",
       "      <td>554.285714</td>\n",
       "      <td>475.942857</td>\n",
       "      <td>461.657143</td>\n",
       "      <td>426.971429</td>\n",
       "      <td>416.000000</td>\n",
       "      <td>514.800000</td>\n",
       "      <td>525.314286</td>\n",
       "      <td>534.693878</td>\n",
       "      <td>4178</td>\n",
       "      <td>Planet_train4179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>650.171429</td>\n",
       "      <td>498.800000</td>\n",
       "      <td>416.342857</td>\n",
       "      <td>413.828571</td>\n",
       "      <td>484.514286</td>\n",
       "      <td>614.571429</td>\n",
       "      <td>635.071429</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>638.800000</td>\n",
       "      <td>622.571429</td>\n",
       "      <td>608.342857</td>\n",
       "      <td>564.228571</td>\n",
       "      <td>687.771429</td>\n",
       "      <td>663.632653</td>\n",
       "      <td>40300</td>\n",
       "      <td>Planet_train40301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>791.257143</td>\n",
       "      <td>678.114286</td>\n",
       "      <td>541.600000</td>\n",
       "      <td>519.828571</td>\n",
       "      <td>761.257143</td>\n",
       "      <td>691.485714</td>\n",
       "      <td>831.214286</td>\n",
       "      <td>711.257143</td>\n",
       "      <td>651.600000</td>\n",
       "      <td>599.257143</td>\n",
       "      <td>708.228571</td>\n",
       "      <td>658.857143</td>\n",
       "      <td>712.800000</td>\n",
       "      <td>719.510204</td>\n",
       "      <td>3161</td>\n",
       "      <td>Planet_train3162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>703.657143</td>\n",
       "      <td>682.057143</td>\n",
       "      <td>485.028571</td>\n",
       "      <td>402.857143</td>\n",
       "      <td>727.257143</td>\n",
       "      <td>633.314286</td>\n",
       "      <td>718.500000</td>\n",
       "      <td>790.857143</td>\n",
       "      <td>754.742857</td>\n",
       "      <td>834.000000</td>\n",
       "      <td>757.600000</td>\n",
       "      <td>781.600000</td>\n",
       "      <td>801.371429</td>\n",
       "      <td>796.897959</td>\n",
       "      <td>3601</td>\n",
       "      <td>Planet_train3602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mg_fold_0   mg_fold_1   mg_fold_2   mg_fold_3   mg_fold_4  mg_all_folds  \\\n",
       "0  729.885714  430.514286  535.314286  556.171429  712.742857    651.485714   \n",
       "1  454.457143  529.771429  465.885714  421.314286  628.114286    560.571429   \n",
       "2  650.171429  498.800000  416.342857  413.828571  484.514286    614.571429   \n",
       "3  791.257143  678.114286  541.600000  519.828571  761.257143    691.485714   \n",
       "4  703.657143  682.057143  485.028571  402.857143  727.257143    633.314286   \n",
       "\n",
       "   mg_best_folds  uniform_fold_0  uniform_fold_1  uniform_fold_2  \\\n",
       "0     742.428571      759.600000      721.371429      726.742857   \n",
       "1     554.285714      475.942857      461.657143      426.971429   \n",
       "2     635.071429      648.000000      638.800000      622.571429   \n",
       "3     831.214286      711.257143      651.600000      599.257143   \n",
       "4     718.500000      790.857143      754.742857      834.000000   \n",
       "\n",
       "   uniform_fold_3  uniform_fold_4  uniform_all_folds  \\\n",
       "0      820.457143      715.371429         797.028571   \n",
       "1      416.000000      514.800000         525.314286   \n",
       "2      608.342857      564.228571         687.771429   \n",
       "3      708.228571      658.857143         712.800000   \n",
       "4      757.600000      781.600000         801.371429   \n",
       "\n",
       "   best_mg_folds_and_all_uniform_folds  planet_idx             planet  \n",
       "0                           778.204082        4449   Planet_train4450  \n",
       "1                           534.693878        4178   Planet_train4179  \n",
       "2                           663.632653       40300  Planet_train40301  \n",
       "3                           719.510204        3161   Planet_train3162  \n",
       "4                           796.897959        3601   Planet_train3602  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict = {\n",
    "    m: scores for m, scores in zip(total_outputs_dict.keys(), posterior_scores_list)\n",
    "}\n",
    "df_posterior_scores = pd.DataFrame(data_dict)\n",
    "df_posterior_scores['planet_idx'] = planet_ids\n",
    "df_posterior_scores['planet'] = df_posterior_scores['planet_idx'].apply(lambda x: f'Planet_train{x+1}')\n",
    "\n",
    "df_posterior_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1c5909ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posterior_scores.to_csv('histories/posterior_scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f52c18",
   "metadata": {},
   "source": [
    "### Spectral scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e0646fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_examples = 10 ## number of test examples to go through\n",
    "N_samples = 10 ## number of quantiles to sample (fixed to 10 in the competition)\n",
    "q_list = np.linspace(0.01, 0.99, N_samples)\n",
    "## beta - weight of the posterior loss [0,1], and the weight of spectral loss will decrease accordingly. \n",
    "beta = 0.8\n",
    "\n",
    "RJUP = 69911000\n",
    "MJUP = 1.898e27\n",
    "RSOL = 696340000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "41abe468",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Path variables\n",
    "opacity_path = \"../ADC_t3_input/xsec/\"\n",
    "CIA_path = \"../ADC_t3_input/cia/HITRAN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d2a254bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## read in spectral grid\n",
    "ariel_wlgrid, ariel_wlwidth, ariel_wngrid, ariel_wnwidth = ariel_resolution()\n",
    "## Initialise base T3 model for ADC2023\n",
    "fm = initialise_forward_model(opacity_path, CIA_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d4e9b7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raed auxillary information from the input file (Provided from ADC2023)\n",
    "aux_df = aux_data.iloc[test_idx]\n",
    "# ensure the dimensionality matches forward model's input.\n",
    "Rs = aux_df['star_radius_m']/RSOL\n",
    "# Rp = aux_df['planet_radius_m']/RJUP\n",
    "Mp = aux_df['planet_mass_kg']/MJUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "801e72c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing mg_fold_0\n",
      "\tfinished after 1178.2593631744385, score: 957.5226928839587\n",
      "processing mg_fold_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\anaconda3\\envs\\tf_bleeding\\lib\\site-packages\\taurex\\model\\simplemodel.py:309: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return (self.pressureProfile)/(KBOLTZ*self.temperatureProfile)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tfinished after 1177.76735830307, score: 910.9787443422043\n",
      "processing mg_fold_2\n",
      "\tfinished after 1175.281938791275, score: 904.5191545363514\n",
      "processing mg_fold_3\n",
      "\tfinished after 1179.2760655879974, score: 878.525482483439\n",
      "processing mg_fold_4\n",
      "\tfinished after 1174.5453746318817, score: 947.8090968601093\n",
      "processing mg_all_folds\n",
      "\tfinished after 1177.6975753307343, score: 919.5214968099411\n",
      "processing mg_best_folds\n",
      "\tfinished after 1177.2504661083221, score: 944.3199240293783\n",
      "processing uniform_fold_0\n",
      "\tfinished after 1173.3180530071259, score: 866.9255286109867\n",
      "processing uniform_fold_1\n",
      "\tfinished after 1173.0261752605438, score: 896.2629955846307\n",
      "processing uniform_fold_2\n",
      "\tfinished after 1178.754096031189, score: 899.0930476287149\n",
      "processing uniform_fold_3\n",
      "\tfinished after 1180.5499951839447, score: 897.607662401769\n",
      "processing uniform_fold_4\n",
      "\tfinished after 1177.5019390583038, score: 895.2954473430315\n",
      "processing uniform_all_folds\n",
      "\tfinished after 1174.2739367485046, score: 880.1497518877807\n",
      "processing best_mg_folds_and_all_uniform_folds\n",
      "\tfinished after 1164.9919760227203, score: 880.4623480016468\n"
     ]
    }
   ],
   "source": [
    "spectral_scores_dict = {}\n",
    "break_idx = 20\n",
    "for _model, tr1 in total_outputs_dict.items():\n",
    "    \n",
    "    ## read in spectral grid\n",
    "    ariel_wlgrid, ariel_wlwidth, ariel_wngrid, ariel_wnwidth = ariel_resolution()\n",
    "    ## Initialise base T3 model for ADC2023\n",
    "    fm = initialise_forward_model(opacity_path, CIA_path)\n",
    "\n",
    "    print(f'processing {_model}')\n",
    "    start_time = time.time()\n",
    "    weights1 = np.ones((tr1.shape[0], tr1.shape[1]))/np.sum(np.ones(tr1.shape[1]))\n",
    "\n",
    "    spectral_scores = []\n",
    "    bounds_matrix = default_prior_bounds()\n",
    "    for idx, pl_idx in enumerate(test_idx):\n",
    "        ## put an early stop here as it will take forever to go through 5000 examples. \n",
    "        if idx == break_idx:\n",
    "            break\n",
    "\n",
    "        tr_GT = trace_GT[f'Planet_train{pl_idx+1}']['tracedata'][()]\n",
    "        weights_GT = trace_GT[f'Planet_train{pl_idx+1}']['weights'][()]\n",
    "\n",
    "        # again to avoid unlabelled data\n",
    "        if np.isnan(tr_GT).sum() == 1:\n",
    "            continue\n",
    "\n",
    "        proxy_compute_spectrum = setup_dedicated_fm(fm, pl_idx, Rs, Mp, ariel_wngrid, ariel_wnwidth)\n",
    "\n",
    "        score = compute_spectral_loss(tr1[idx], weights1[idx], tr_GT, weights_GT, bounds_matrix, proxy_compute_spectrum, q_list)\n",
    "        spectral_scores.append(score)\n",
    "        \n",
    "    spectral_scores_dict[_model] = spectral_scores\n",
    "    avg_spectral_score = np.mean(spectral_scores)\n",
    "    print(f'\\tfinished after {time.time() - start_time}, score: {avg_spectral_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c7f8effe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mg_fold_0</th>\n",
       "      <th>mg_fold_1</th>\n",
       "      <th>mg_fold_2</th>\n",
       "      <th>mg_fold_3</th>\n",
       "      <th>mg_fold_4</th>\n",
       "      <th>mg_all_folds</th>\n",
       "      <th>mg_best_folds</th>\n",
       "      <th>uniform_fold_0</th>\n",
       "      <th>uniform_fold_1</th>\n",
       "      <th>uniform_fold_2</th>\n",
       "      <th>uniform_fold_3</th>\n",
       "      <th>uniform_fold_4</th>\n",
       "      <th>uniform_all_folds</th>\n",
       "      <th>best_mg_folds_and_all_uniform_folds</th>\n",
       "      <th>planet_idx</th>\n",
       "      <th>planet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>952.201680</td>\n",
       "      <td>949.339451</td>\n",
       "      <td>881.959938</td>\n",
       "      <td>867.636232</td>\n",
       "      <td>960.755411</td>\n",
       "      <td>921.445083</td>\n",
       "      <td>918.318939</td>\n",
       "      <td>849.863256</td>\n",
       "      <td>874.229691</td>\n",
       "      <td>893.023334</td>\n",
       "      <td>828.178355</td>\n",
       "      <td>886.750861</td>\n",
       "      <td>884.820104</td>\n",
       "      <td>810.976895</td>\n",
       "      <td>4449</td>\n",
       "      <td>Planet_train4450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>950.029558</td>\n",
       "      <td>935.977619</td>\n",
       "      <td>858.241188</td>\n",
       "      <td>835.340677</td>\n",
       "      <td>908.222888</td>\n",
       "      <td>895.379315</td>\n",
       "      <td>949.248473</td>\n",
       "      <td>910.916970</td>\n",
       "      <td>912.018312</td>\n",
       "      <td>916.742764</td>\n",
       "      <td>848.512629</td>\n",
       "      <td>861.548007</td>\n",
       "      <td>876.055451</td>\n",
       "      <td>883.248706</td>\n",
       "      <td>4178</td>\n",
       "      <td>Planet_train4179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>958.507064</td>\n",
       "      <td>955.124329</td>\n",
       "      <td>898.463089</td>\n",
       "      <td>900.969192</td>\n",
       "      <td>952.263389</td>\n",
       "      <td>899.657768</td>\n",
       "      <td>950.478039</td>\n",
       "      <td>863.731255</td>\n",
       "      <td>886.121280</td>\n",
       "      <td>852.081369</td>\n",
       "      <td>849.691788</td>\n",
       "      <td>958.046511</td>\n",
       "      <td>850.318887</td>\n",
       "      <td>824.582117</td>\n",
       "      <td>40300</td>\n",
       "      <td>Planet_train40301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>959.052647</td>\n",
       "      <td>905.483897</td>\n",
       "      <td>891.432166</td>\n",
       "      <td>900.978088</td>\n",
       "      <td>949.049141</td>\n",
       "      <td>890.762040</td>\n",
       "      <td>952.955071</td>\n",
       "      <td>876.598214</td>\n",
       "      <td>909.930267</td>\n",
       "      <td>925.109010</td>\n",
       "      <td>910.716040</td>\n",
       "      <td>875.660351</td>\n",
       "      <td>864.294612</td>\n",
       "      <td>857.223097</td>\n",
       "      <td>3161</td>\n",
       "      <td>Planet_train3162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>983.491578</td>\n",
       "      <td>982.571990</td>\n",
       "      <td>964.037836</td>\n",
       "      <td>969.319307</td>\n",
       "      <td>979.004825</td>\n",
       "      <td>966.370451</td>\n",
       "      <td>973.763028</td>\n",
       "      <td>975.537935</td>\n",
       "      <td>963.855397</td>\n",
       "      <td>953.846054</td>\n",
       "      <td>953.029152</td>\n",
       "      <td>959.018311</td>\n",
       "      <td>947.580263</td>\n",
       "      <td>958.546885</td>\n",
       "      <td>3601</td>\n",
       "      <td>Planet_train3602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mg_fold_0   mg_fold_1   mg_fold_2   mg_fold_3   mg_fold_4  mg_all_folds  \\\n",
       "0  952.201680  949.339451  881.959938  867.636232  960.755411    921.445083   \n",
       "1  950.029558  935.977619  858.241188  835.340677  908.222888    895.379315   \n",
       "2  958.507064  955.124329  898.463089  900.969192  952.263389    899.657768   \n",
       "3  959.052647  905.483897  891.432166  900.978088  949.049141    890.762040   \n",
       "4  983.491578  982.571990  964.037836  969.319307  979.004825    966.370451   \n",
       "\n",
       "   mg_best_folds  uniform_fold_0  uniform_fold_1  uniform_fold_2  \\\n",
       "0     918.318939      849.863256      874.229691      893.023334   \n",
       "1     949.248473      910.916970      912.018312      916.742764   \n",
       "2     950.478039      863.731255      886.121280      852.081369   \n",
       "3     952.955071      876.598214      909.930267      925.109010   \n",
       "4     973.763028      975.537935      963.855397      953.846054   \n",
       "\n",
       "   uniform_fold_3  uniform_fold_4  uniform_all_folds  \\\n",
       "0      828.178355      886.750861         884.820104   \n",
       "1      848.512629      861.548007         876.055451   \n",
       "2      849.691788      958.046511         850.318887   \n",
       "3      910.716040      875.660351         864.294612   \n",
       "4      953.029152      959.018311         947.580263   \n",
       "\n",
       "   best_mg_folds_and_all_uniform_folds  planet_idx             planet  \n",
       "0                           810.976895        4449   Planet_train4450  \n",
       "1                           883.248706        4178   Planet_train4179  \n",
       "2                           824.582117       40300  Planet_train40301  \n",
       "3                           857.223097        3161   Planet_train3162  \n",
       "4                           958.546885        3601   Planet_train3602  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict = {\n",
    "    m: scores for m, scores in spectral_scores_dict.items()\n",
    "}\n",
    "df_spectral_scores = pd.DataFrame(data_dict)\n",
    "df_spectral_scores['planet_idx'] = planet_ids[:break_idx]\n",
    "df_spectral_scores['planet'] = df_spectral_scores['planet_idx'].apply(lambda x: f'Planet_train{x+1}')\n",
    "\n",
    "df_spectral_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e47cc5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spectral_scores.to_csv('histories/spectral_scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e39870a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
